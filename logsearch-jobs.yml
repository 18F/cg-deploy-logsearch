instance_groups:
###############################################################################
#First deploy group - elasticsearch_master, cluster_monitor, queue, maintenance
###############################################################################
- name: elasticsearch_master
  instances: 1
  jobs:
  - name: elasticsearch
    release: logsearch
    properties:
      elasticsearch:
        node:
          allow_master: true
          allow_data: false
        master_hosts: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips ))
        cluster_name: logsearch
        exec:
          environment:
            JAVA_OPTS: '"-Djava.io.tmpdir=${TMP_DIR}"'
        limits:
          fd: 131072  # 2 ** 17
        health:
          timeout: 900
        recovery:
          delay_allocation_restart: "15m"
  - name: riemann-emitter
    release: riemann
    properties:
      riemann_emitter:
        elastic:
          host: 127.0.0.1
          port: 9200
  - name: riemann-checklogs
    release: riemann
  - name: snort-config
    release: snort
    properties:
      snort:
        rules:
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"POST"; http_method; content: "logs-app"; http_uri; content:"/_update"; http_uri; classtype:web-application-attack; sid:343080002; rev:1;)'
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"POST"; http_method; content: "logs-platform"; http_uri; content:"/_update"; http_uri; classtype:web-application-attack; sid:343080003; rev:1;)'
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"DELETE"; http_method; content: "logs-app"; http_uri; classtype:web-application-attack; sid:343080004; rev:1;)'
        - (( concat "suppress gen_id 1, sig_id 343080004, track by_src, ip " instance_groups.cluster_monitor.networks.logsearch.static_ips.[0] ))
        - 'alert tcp any any -> any 9200 (msg:"Unexpected logsearch action"; content:"DELETE"; http_method; content: "logs-platform"; http_uri; classtype:web-application-attack; sid:343080005; rev:1;)'
        - (( concat "suppress gen_id 1, sig_id 343080005, track by_src, ip " instance_groups.cluster_monitor.networks.logsearch.static_ips.[0] ))
  vm_type: logsearch_es_master
  persistent_disk_type: logsearch_es_master
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
    static_ips:
    - (( grab terraform_outputs.logsearch_static_ips.[0] ))
  update:
    max_in_flight: 1 # Should never update more than one ES master node at a time or cluster will go down

- name: cluster_monitor
  instances: 1
  jobs:
  - release: logsearch
    name: queue
    properties:
      redis:
        host: 127.0.0.1
        maxmemory: 10
  - release: logsearch
    name: parser
    properties:
      redis: (( grab instance_groups.cluster_monitor.jobs.queue.properties.redis ))
      logstash_parser:
        filters:
        - monitor: /var/vcap/packages/logsearch-config/logstash-filters-monitor.conf
  - release: logsearch
    name: ingestor_syslog
    properties:
      redis: (( grab instance_groups.cluster_monitor.jobs.queue.properties.redis ))
      logstash_ingestor:
        syslog:
          port: 514
  - release: logsearch
    name: elasticsearch
    properties:
      elasticsearch:
        master_hosts: [127.0.0.1]
        cluster_name: monitor
        node:
          allow_master: true
          allow_data: true
  - release: logsearch
    name: elasticsearch_config
    properties:
      elasticsearch_config:
        elasticsearch:
          host: 127.0.0.1
          port: 9200
  - release: logsearch
    name: kibana
    properties:
      kibana:
        port: 5601
        elasticsearch:
          host: 127.0.0.1
          port: 9200
        memory_limit: 30
        wait_for_templates: [shards-and-replicas]
  - release: logsearch
    name: nats_to_syslog
  vm_type: logsearch_cluster_monitor
  persistent_disk_type: logsearch_cluster_monitor
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
    static_ips:
    - (( grab terraform_outputs.logsearch_static_ips.[2] ))

- name: queue
  instances: 1
  jobs:
  - {name: queue, release: logsearch}
  vm_type: logsearch_queue
  persistent_disk_type: logsearch_queue
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
    static_ips:
    - (( grab terraform_outputs.logsearch_static_ips.[3] ))

- name: maintenance
  instances: 1
  jobs:
  - name: curator
    release: logsearch
    properties:
      curator:
        purge_logs:
          retention_period: 180
        elasticsearch:
          host: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips.[0] ))
          port: 9200
  - name: elasticsearch_config
    release: logsearch
    properties:
      elasticsearch_config:
        templates:
        - shards-and-replicas: /var/vcap/jobs/elasticsearch_config/index-templates/shards-and-replicas.json
        - index-settings: /var/vcap/jobs/elasticsearch_config/index-templates/index-settings.json
        - index-mappings: /var/vcap/jobs/elasticsearch_config/index-templates/index-mappings.json
        - index-mappings-lfc: /var/vcap/jobs/elasticsearch-config-lfc/index-mappings.json
        - index-mappings-app-lfc: /var/vcap/jobs/elasticsearch-config-lfc/index-mappings-app.json
        - index-mappings-platform-lfc: /var/vcap/jobs/elasticsearch-config-lfc/index-mappings-platform.json
        elasticsearch:
          host: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips.[0] ))
  - name: elasticsearch-config-lfc
    release: logsearch-for-cloudfoundry
  vm_type: logsearch_maintenance
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
  update:
    serial: true # Block on this job to create deploy group 1

##################################################################
#2nd deploy group - elasticsearch_data, kibana, ingestors, parsers
##################################################################

- name: elasticsearch_data
  instances: 6
  jobs:
  - name: elasticsearch
    release: logsearch
    properties:
      elasticsearch:
        node:
          allow_master: false
          allow_data: true
        master_hosts: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips ))
        cluster_name: logsearch
        exec:
          environment:
            JAVA_OPTS: '"-Djava.io.tmpdir=${TMP_DIR}"'
        limits:
          fd: 131072  # 2 ** 17
        health:
          timeout: 900
        recovery:
          delay_allocation_restart: "15m"
  vm_type: logsearch_es_data
  persistent_disk_type: logsearch_es_data
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
    static_ips:
    - (( grab terraform_outputs.logsearch_static_ips.[16]))
    - (( grab terraform_outputs.logsearch_static_ips.[17]))
    - (( grab terraform_outputs.logsearch_static_ips.[14]))
    - (( grab terraform_outputs.logsearch_static_ips.[15]))
    - (( grab terraform_outputs.logsearch_static_ips.[13]))
    - (( grab terraform_outputs.logsearch_static_ips.[12]))
  update:
    max_in_flight: 1 # Only update 1 ES data node at a time or risk downtime

- name: kibana
  instances: 1
  jobs: 
  - name: kibana
    release: logsearch
    properties:
      kibana:
        memory_limit: 65
        default_app_id: "dashboard/App-Overview"
        plugins:
        - auth: /var/vcap/packages/kibana-auth-plugin/kibana-auth-plugin.zip
        config_options: |-
          console.enabled: false
        elasticsearch:
          host: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips.[0] ))
          port: 9200
        env:
        - KIBANA_OAUTH2_CLIENT_ID: kibana_oauth2_client
        - SKIP_SSL_VALIDATION: false
        - CF_SYSTEM_ORG: cloud-gov-operators # Org Managers of this org get admin access
        - REDIS_HOST: (( grab instance_groups.queue.networks.logsearch.static_ips.[0] ))
  - name: kibana-auth-plugin
    release: logsearch-for-cloudfoundry
  vm_type: logsearch_kibana
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
    static_ips: 
    - (( grab terraform_outputs.logsearch_static_ips.[5] ))

- name: ingestor
  jobs:
  - name: ingestor_syslog
    release: logsearch
    properties:
      logstash_ingestor:
        outputs:
        - plugin: redis
          options: {}
        - plugin: s3
          options:
            region: (( grab terraform_outputs.vpc_region ))
            bucket: (( grab terraform_outputs.logsearch_archive_bucket_name ))
            validate_credentials_on_root_bucket: false  # https://github.com/logstash-plugins/logstash-output-s3/issues/132
            server_side_encryption: true
            time_file: 5
        relp:
          port: ~
      redis:
        host: (( grab instance_groups.queue.networks.logsearch.static_ips.[0] ))
  - name: ingestor_cloudfoundry-firehose
    release: logsearch-for-cloudfoundry
    properties:
      cloudfoundry:
        firehose_events: "LogMessage,ContainerMetric"
        firehose_client_id: logsearch_firehose_ingestor
        skip_ssl_validation: false
    syslog:
        host: (( grab instance_groups.ingestor.networks.logsearch.static_ips.[0] ))
        port: 5514
  vm_type: logsearch_ingestor
  stemcell: default
  azs: [z1]
  vm_extensions: [logsearch-ingestor-profile]

- name: parser
  instances: 2
  jobs:
  - name: parser
    release: logsearch
    properties:
      logstash_parser:
        elasticsearch:
          # Use per-day indexing strategy
          index: "logs-%{@index_type}-%{+YYYY.MM.dd}"
          index_type: "%{@type}"
        filters:
        - logsearch-for-cf: /var/vcap/packages/logsearch-config-logstash-filters/logstash-filters-default.conf
        deployment_dictionary:
        - /var/vcap/packages/logsearch-config/deployment_lookup.yml
        - /var/vcap/jobs/parser-config-lfc/config/deployment_lookup.yml
      redis:
        host: (( grab instance_groups.queue.networks.logsearch.static_ips.[0] ))
  - name: elasticsearch
    release: logsearch
    properties:
      elasticsearch: 
        master_hosts: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips ))
        cluster_name: logsearch
        exec:
          environment:
            JAVA_OPTS: '"-Djava.io.tmpdir=${TMP_DIR}"'
        limits:
          fd: 131072  # 2 ** 17
        health:
          timeout: 900
        recovery:
          delay_allocation_restart: "15m"
  - name: parser-config-lfc
    release: logsearch-for-cloudfoundry
  vm_type: logsearch_parser
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
  update:
    serial: false # Block to create deploy group 2
    max_in_flight: 4  # Its ok to update multiple parsers at a time

####################################################
#3nd deploy group - ls-router (haproxy), and errands
####################################################

- name: ls-router
  instances: 1
  jobs:
  - name: haproxy
    release: logsearch
    properties:
      haproxy:
        syslog_server: (( grab instance_groups.cluster_monitor.networks.logsearch.static_ips.[0] ))
        ingestor:
          backend_servers: (( grab instance_groups.ingestor.networks.logsearch.static_ips ))
        kibana:
    release: logsearch
    properties:
      haproxy:
        syslog_server: (( grab instance_groups.cluster_monitor.networks.logsearch.static_ips.[0] ))
        ingestor:
          backend_servers: (( grab instance_groups.ingestor.networks.logsearch.static_ips ))
        kibana:
          backend_servers: (( grab instance_groups.kibana.networks.logsearch.static_ips ))
        cluster_monitor:
          backend_servers: (( grab instance_groups.cluster_monitor.networks.logsearch.static_ips ))
  - name: route_registrar
    release: cf
  vm_type: logsearch_haproxy
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
    static_ips: 
    - (( grab terraform_outputs.logsearch_static_ips.[9] ))

- name: smoke-tests
  instances: 1
  vm_type: logsearch_errand
  vm_extensions: [logsearch-errand-profile]
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
  lifecycle: errand
  release: logsearch
  jobs:
  - name: smoke-tests
    release: logsearch
    properties:
      smoke_tests:
        syslog_ingestor:
          host: (( grab instance_groups.ls-router.networks.logsearch.static_ips.[0] ))
        elasticsearch_master:
          host: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips.[0] ))

- name: upload-kibana-objects
  instances: 1
  vm_type: logsearch_errand
  vm_extensions: [logsearch-errand-profile]
  stemcell: default
  azs: [z1]
  networks:
  - name: logsearch
  lifecycle: errand
  release: logsearch-for-cloudfoundry
  jobs:
  - name: upload-kibana-objects
    release: logsearch-for-cloudfoundry
    properties:
      elasticsearch:
        host: (( grab instance_groups.elasticsearch_master.networks.logsearch.static_ips.[0] ))
        port: 9200
      kibana_objects:
        upload_patterns:
